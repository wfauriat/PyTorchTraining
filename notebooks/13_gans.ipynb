{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 13: Generative Adversarial Networks (GANs)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand the GAN framework: generator vs discriminator\n",
    "2. Implement and train a basic GAN on MNIST\n",
    "3. Build a Deep Convolutional GAN (DCGAN)\n",
    "4. Understand training challenges and solutions (WGAN, WGAN-GP)\n",
    "\n",
    "**Prerequisites**: Notebooks 01-04, 07 (CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. GAN Theory: A Two-Player Game\n",
    "\n",
    "GANs consist of two networks playing a minimax game:\n",
    "\n",
    "- **Generator (G)**: Creates fake samples from random noise\n",
    "- **Discriminator (D)**: Distinguishes real from fake samples\n",
    "\n",
    "```\n",
    "Noise z ~ N(0,1) → [Generator] → Fake image\n",
    "                                    ↓\n",
    "Real image ──────────────────→ [Discriminator] → Real/Fake?\n",
    "```\n",
    "\n",
    "### The Minimax Objective\n",
    "\n",
    "$$\\min_G \\max_D \\mathbb{E}_{x \\sim p_{data}}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z}[\\log(1 - D(G(z)))]$$\n",
    "\n",
    "- **D wants to maximize**: correctly classify real as real, fake as fake\n",
    "- **G wants to minimize**: make D classify fake as real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])  # Scale to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Simple GAN (MLP-based)\n",
    "\n",
    "Let's start with a basic fully-connected GAN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"MLP Generator: noise → image\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, img_dim=784):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh()  # Output in [-1, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.net(z).view(-1, 1, 28, 28)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"MLP Discriminator: image → real/fake probability\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dim=784):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(img_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.net(img.view(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(generator, n=16, latent_dim=100):\n",
    "    \"\"\"Generate and display samples.\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n, latent_dim).to(device)\n",
    "        samples = generator(z)\n",
    "    \n",
    "    # Denormalize from [-1,1] to [0,1]\n",
    "    samples = (samples + 1) / 2\n",
    "    \n",
    "    grid = make_grid(samples, nrow=int(np.sqrt(n)), padding=2)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(grid.cpu().permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    generator.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(G, D, train_loader, epochs=50, latent_dim=100, lr=2e-4):\n",
    "    \"\"\"Train GAN with standard binary cross-entropy loss.\"\"\"\n",
    "    \n",
    "    opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    opt_D = torch.optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    history = {'d_loss': [], 'g_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        d_loss_sum, g_loss_sum = 0, 0\n",
    "        \n",
    "        for real_imgs, _ in train_loader:\n",
    "            batch_size = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            \n",
    "            # Labels\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "            \n",
    "            # ==================\n",
    "            # Train Discriminator\n",
    "            # ==================\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = G(z).detach()  # Don't compute G gradients\n",
    "            \n",
    "            d_real = D(real_imgs)\n",
    "            d_fake = D(fake_imgs)\n",
    "            \n",
    "            d_loss = criterion(d_real, real_labels) + criterion(d_fake, fake_labels)\n",
    "            \n",
    "            opt_D.zero_grad()\n",
    "            d_loss.backward()\n",
    "            opt_D.step()\n",
    "            \n",
    "            # ===============\n",
    "            # Train Generator\n",
    "            # ===============\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = G(z)\n",
    "            d_fake = D(fake_imgs)\n",
    "            \n",
    "            # G wants D to think fakes are real\n",
    "            g_loss = criterion(d_fake, real_labels)\n",
    "            \n",
    "            opt_G.zero_grad()\n",
    "            g_loss.backward()\n",
    "            opt_G.step()\n",
    "            \n",
    "            d_loss_sum += d_loss.item()\n",
    "            g_loss_sum += g_loss.item()\n",
    "        \n",
    "        n = len(train_loader)\n",
    "        history['d_loss'].append(d_loss_sum / n)\n",
    "        history['g_loss'].append(g_loss_sum / n)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - D Loss: {d_loss_sum/n:.4f}, G Loss: {g_loss_sum/n:.4f}\")\n",
    "            show_samples(G, n=16, latent_dim=latent_dim)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train simple GAN\n",
    "latent_dim = 100\n",
    "G = Generator(latent_dim).to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "history = train_gan(G, D, train_loader, epochs=50, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history['d_loss'], label='Discriminator')\n",
    "plt.plot(history['g_loss'], label='Generator')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('GAN Training Losses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Deep Convolutional GAN (DCGAN)\n",
    "\n",
    "DCGANs use convolutional layers for better image quality. Key architecture guidelines:\n",
    "- Use strided convolutions (no pooling)\n",
    "- BatchNorm in both G and D (except output layers)\n",
    "- ReLU in G, LeakyReLU in D\n",
    "- Tanh output in G, no activation in D output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGenerator(nn.Module):\n",
    "    \"\"\"DCGAN Generator for 28x28 images.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=100, channels=1):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Project and reshape: latent_dim -> 256x7x7\n",
    "        self.fc = nn.Linear(latent_dim, 256 * 7 * 7)\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            # 256x7x7 -> 128x14x14\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # 128x14x14 -> 1x28x28\n",
    "            nn.ConvTranspose2d(128, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        x = self.fc(z).view(-1, 256, 7, 7)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    \"\"\"DCGAN Discriminator for 28x28 images.\"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            # 1x28x28 -> 64x14x14\n",
    "            nn.Conv2d(channels, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # 64x14x14 -> 128x7x7\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        features = self.conv(img)\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"Initialize weights as recommended for DCGAN.\"\"\"\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "# Initialize DCGAN\n",
    "latent_dim = 100\n",
    "dc_G = DCGenerator(latent_dim).to(device)\n",
    "dc_D = DCDiscriminator().to(device)\n",
    "dc_G.apply(weights_init)\n",
    "dc_D.apply(weights_init)\n",
    "\n",
    "print(f\"Generator params: {sum(p.numel() for p in dc_G.parameters()):,}\")\n",
    "print(f\"Discriminator params: {sum(p.numel() for p in dc_D.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DCGAN\n",
    "dc_history = train_gan(dc_G, dc_D, train_loader, epochs=50, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final samples from DCGAN\n",
    "print(\"DCGAN Generated Samples:\")\n",
    "show_samples(dc_G, n=25, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. GAN Training Challenges\n",
    "\n",
    "GANs are notoriously difficult to train. Common issues:\n",
    "\n",
    "### Mode Collapse\n",
    "Generator produces limited variety of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_mode_collapse(generator, n_samples=100, latent_dim=100):\n",
    "    \"\"\"Check for mode collapse by measuring output diversity.\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n_samples, latent_dim).to(device)\n",
    "        samples = generator(z).view(n_samples, -1)\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        dists = torch.cdist(samples, samples)\n",
    "        # Exclude diagonal (self-distances)\n",
    "        mask = ~torch.eye(n_samples, dtype=bool, device=device)\n",
    "        mean_dist = dists[mask].mean().item()\n",
    "        min_dist = dists[mask].min().item()\n",
    "    \n",
    "    print(f\"Mean pairwise distance: {mean_dist:.4f}\")\n",
    "    print(f\"Min pairwise distance: {min_dist:.4f}\")\n",
    "    print(\"(Low values suggest mode collapse)\")\n",
    "    generator.train()\n",
    "\n",
    "check_mode_collapse(dc_G, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanishing Gradients\n",
    "When D is too strong, G gets no learning signal.\n",
    "\n",
    "### Training Instability\n",
    "Losses oscillate wildly; one network dominates.\n",
    "\n",
    "---\n",
    "## 5. Wasserstein GAN (WGAN)\n",
    "\n",
    "WGAN addresses training instability by using the Wasserstein distance instead of JS divergence.\n",
    "\n",
    "### Key Changes:\n",
    "1. **No sigmoid in D** (now called \"critic\")\n",
    "2. **Wasserstein loss**: $L_D = D(fake) - D(real)$, $L_G = -D(fake)$\n",
    "3. **Weight clipping** to enforce Lipschitz constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WCritic(nn.Module):\n",
    "    \"\"\"WGAN Critic (no sigmoid).\"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(channels, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1)  # No sigmoid!\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan(G, C, train_loader, epochs=50, latent_dim=100, \n",
    "               lr=5e-5, n_critic=5, clip_value=0.01):\n",
    "    \"\"\"Train WGAN with weight clipping.\"\"\"\n",
    "    \n",
    "    opt_G = torch.optim.RMSprop(G.parameters(), lr=lr)\n",
    "    opt_C = torch.optim.RMSprop(C.parameters(), lr=lr)\n",
    "    \n",
    "    history = {'c_loss': [], 'g_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        c_loss_sum, g_loss_sum = 0, 0\n",
    "        g_steps = 0\n",
    "        \n",
    "        for i, (real_imgs, _) in enumerate(train_loader):\n",
    "            batch_size = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            \n",
    "            # ==============\n",
    "            # Train Critic (more frequently)\n",
    "            # ==============\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = G(z).detach()\n",
    "            \n",
    "            # Wasserstein loss: maximize C(real) - C(fake)\n",
    "            c_loss = C(fake_imgs).mean() - C(real_imgs).mean()\n",
    "            \n",
    "            opt_C.zero_grad()\n",
    "            c_loss.backward()\n",
    "            opt_C.step()\n",
    "            \n",
    "            # Weight clipping\n",
    "            for p in C.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "            \n",
    "            c_loss_sum += c_loss.item()\n",
    "            \n",
    "            # ===============\n",
    "            # Train Generator (less frequently)\n",
    "            # ===============\n",
    "            if (i + 1) % n_critic == 0:\n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = G(z)\n",
    "                \n",
    "                # G wants to maximize C(fake)\n",
    "                g_loss = -C(fake_imgs).mean()\n",
    "                \n",
    "                opt_G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                opt_G.step()\n",
    "                \n",
    "                g_loss_sum += g_loss.item()\n",
    "                g_steps += 1\n",
    "        \n",
    "        history['c_loss'].append(c_loss_sum / len(train_loader))\n",
    "        history['g_loss'].append(g_loss_sum / max(g_steps, 1))\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - C Loss: {history['c_loss'][-1]:.4f}, \"\n",
    "                  f\"G Loss: {history['g_loss'][-1]:.4f}\")\n",
    "            show_samples(G, n=16, latent_dim=latent_dim)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train WGAN\n",
    "wgan_G = DCGenerator(latent_dim).to(device)\n",
    "wgan_C = WCritic().to(device)\n",
    "wgan_G.apply(weights_init)\n",
    "wgan_C.apply(weights_init)\n",
    "\n",
    "wgan_history = train_wgan(wgan_G, wgan_C, train_loader, epochs=50, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. WGAN with Gradient Penalty (WGAN-GP)\n",
    "\n",
    "Weight clipping can cause issues. WGAN-GP uses a **gradient penalty** instead to enforce the Lipschitz constraint:\n",
    "\n",
    "$$L = L_{WGAN} + \\lambda \\mathbb{E}_{\\hat{x}}[(\\|\\nabla_{\\hat{x}} D(\\hat{x})\\|_2 - 1)^2]$$\n",
    "\n",
    "Where $\\hat{x}$ is interpolated between real and fake samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake):\n",
    "    \"\"\"Compute gradient penalty for WGAN-GP.\"\"\"\n",
    "    batch_size = real.size(0)\n",
    "    \n",
    "    # Random interpolation coefficient\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    \n",
    "    # Interpolate between real and fake\n",
    "    interpolated = alpha * real + (1 - alpha) * fake\n",
    "    interpolated.requires_grad_(True)\n",
    "    \n",
    "    # Critic score on interpolated\n",
    "    critic_interp = critic(interpolated)\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=critic_interp,\n",
    "        inputs=interpolated,\n",
    "        grad_outputs=torch.ones_like(critic_interp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    # Gradient norm penalty\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    grad_norm = gradients.norm(2, dim=1)\n",
    "    penalty = ((grad_norm - 1) ** 2).mean()\n",
    "    \n",
    "    return penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WCriticGP(nn.Module):\n",
    "    \"\"\"WGAN-GP Critic (no BatchNorm - interferes with GP).\"\"\"\n",
    "    \n",
    "    def __init__(self, channels=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(channels, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.InstanceNorm2d(128),  # InstanceNorm instead of BatchNorm\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.net(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_gp(G, C, train_loader, epochs=50, latent_dim=100,\n",
    "                  lr=1e-4, n_critic=5, lambda_gp=10):\n",
    "    \"\"\"Train WGAN with gradient penalty.\"\"\"\n",
    "    \n",
    "    opt_G = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "    opt_C = torch.optim.Adam(C.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "    \n",
    "    history = {'c_loss': [], 'g_loss': [], 'gp': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        c_loss_sum, g_loss_sum, gp_sum = 0, 0, 0\n",
    "        g_steps = 0\n",
    "        \n",
    "        for i, (real_imgs, _) in enumerate(train_loader):\n",
    "            batch_size = real_imgs.size(0)\n",
    "            real_imgs = real_imgs.to(device)\n",
    "            \n",
    "            # ==============\n",
    "            # Train Critic\n",
    "            # ==============\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_imgs = G(z).detach()\n",
    "            \n",
    "            c_real = C(real_imgs).mean()\n",
    "            c_fake = C(fake_imgs).mean()\n",
    "            gp = gradient_penalty(C, real_imgs, fake_imgs)\n",
    "            \n",
    "            c_loss = c_fake - c_real + lambda_gp * gp\n",
    "            \n",
    "            opt_C.zero_grad()\n",
    "            c_loss.backward()\n",
    "            opt_C.step()\n",
    "            \n",
    "            c_loss_sum += c_loss.item()\n",
    "            gp_sum += gp.item()\n",
    "            \n",
    "            # ===============\n",
    "            # Train Generator\n",
    "            # ===============\n",
    "            if (i + 1) % n_critic == 0:\n",
    "                z = torch.randn(batch_size, latent_dim).to(device)\n",
    "                fake_imgs = G(z)\n",
    "                \n",
    "                g_loss = -C(fake_imgs).mean()\n",
    "                \n",
    "                opt_G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                opt_G.step()\n",
    "                \n",
    "                g_loss_sum += g_loss.item()\n",
    "                g_steps += 1\n",
    "        \n",
    "        n = len(train_loader)\n",
    "        history['c_loss'].append(c_loss_sum / n)\n",
    "        history['g_loss'].append(g_loss_sum / max(g_steps, 1))\n",
    "        history['gp'].append(gp_sum / n)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - C: {history['c_loss'][-1]:.4f}, \"\n",
    "                  f\"G: {history['g_loss'][-1]:.4f}, GP: {history['gp'][-1]:.4f}\")\n",
    "            show_samples(G, n=16, latent_dim=latent_dim)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train WGAN-GP\n",
    "wgangp_G = DCGenerator(latent_dim).to(device)\n",
    "wgangp_C = WCriticGP().to(device)\n",
    "wgangp_G.apply(weights_init)\n",
    "\n",
    "wgangp_history = train_wgan_gp(wgangp_G, wgangp_C, train_loader, epochs=50, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all methods\n",
    "print(\"Final samples comparison:\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "for ax, (name, gen) in zip(axes, [('DCGAN', dc_G), ('WGAN', wgan_G), ('WGAN-GP', wgangp_G)]):\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(16, latent_dim).to(device)\n",
    "        samples = (gen(z) + 1) / 2\n",
    "    grid = make_grid(samples, nrow=4, padding=2)\n",
    "    ax.imshow(grid.cpu().permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "    ax.set_title(name)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Latent Space Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_latent(generator, z1, z2, steps=10):\n",
    "    \"\"\"Interpolate between two latent vectors.\"\"\"\n",
    "    generator.eval()\n",
    "    alphas = torch.linspace(0, 1, steps).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        interpolations = []\n",
    "        for alpha in alphas:\n",
    "            z = (1 - alpha) * z1 + alpha * z2\n",
    "            img = generator(z.unsqueeze(0))\n",
    "            interpolations.append(img)\n",
    "    \n",
    "    return torch.cat(interpolations)\n",
    "\n",
    "# Interpolate\n",
    "z1 = torch.randn(latent_dim).to(device)\n",
    "z2 = torch.randn(latent_dim).to(device)\n",
    "\n",
    "interp = interpolate_latent(wgangp_G, z1, z2, steps=10)\n",
    "interp = (interp + 1) / 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 1.5))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(interp[i].cpu().squeeze(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Latent Space Interpolation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_arithmetic(generator, latent_dim):\n",
    "    \"\"\"Demonstrate latent space arithmetic.\"\"\"\n",
    "    generator.eval()\n",
    "    \n",
    "    # Generate several samples and find interesting directions\n",
    "    with torch.no_grad():\n",
    "        z_base = torch.randn(1, latent_dim).to(device)\n",
    "        \n",
    "        # Vary different dimensions\n",
    "        fig, axes = plt.subplots(5, 11, figsize=(15, 7))\n",
    "        \n",
    "        for row, dim in enumerate([0, 10, 25, 50, 75]):\n",
    "            for col, val in enumerate(np.linspace(-3, 3, 11)):\n",
    "                z = z_base.clone()\n",
    "                z[0, dim] = val\n",
    "                img = generator(z)\n",
    "                img = (img + 1) / 2\n",
    "                axes[row, col].imshow(img[0].cpu().squeeze(), cmap='gray')\n",
    "                axes[row, col].axis('off')\n",
    "            axes[row, 0].set_ylabel(f'dim {dim}', fontsize=10)\n",
    "        \n",
    "        plt.suptitle('Varying individual latent dimensions')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "latent_arithmetic(wgangp_G, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary\n",
    "\n",
    "### GAN Variants Comparison\n",
    "\n",
    "| Variant | Loss | Constraint | Pros | Cons |\n",
    "|---------|------|------------|------|------|\n",
    "| **GAN** | BCE | None | Simple | Unstable, mode collapse |\n",
    "| **WGAN** | Wasserstein | Weight clipping | More stable | Slow, capacity issues |\n",
    "| **WGAN-GP** | Wasserstein + GP | Gradient penalty | Best stability | Slower per step |\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Generator** | Maps noise z → fake images |\n",
    "| **Discriminator/Critic** | Classifies real vs fake |\n",
    "| **Mode Collapse** | G produces limited variety |\n",
    "| **Wasserstein Distance** | Earth mover's distance, more stable gradients |\n",
    "| **Gradient Penalty** | Enforces Lipschitz constraint on critic |\n",
    "\n",
    "### Training Tips\n",
    "\n",
    "1. Use LeakyReLU in discriminator\n",
    "2. Use BatchNorm (except WGAN-GP critic)\n",
    "3. Adam with β₁=0.5 for standard GAN\n",
    "4. Train D more than G (n_critic=5 for WGAN)\n",
    "5. Monitor for mode collapse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Conditional GAN (cGAN)\n",
    "Modify the DCGAN to condition on class labels, enabling generation of specific digits.\n",
    "\n",
    "### Exercise 2: Fashion-MNIST GAN\n",
    "Train a WGAN-GP on Fashion-MNIST. Compare generated clothing items.\n",
    "\n",
    "### Exercise 3: Training Stability Analysis\n",
    "Compare training curves of GAN, WGAN, and WGAN-GP over 100 epochs. Which is most stable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Conditional GAN\n",
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, 50)\n",
    "        \n",
    "        self.fc = nn.Linear(latent_dim + 50, 256 * 7 * 7)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        label_emb = self.label_emb(labels)\n",
    "        x = torch.cat([z, label_emb], dim=1)\n",
    "        x = self.fc(x).view(-1, 256, 7, 7)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, 28 * 28)\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(2, 64, 4, 2, 1),  # 2 channels: image + label\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, labels):\n",
    "        label_map = self.label_emb(labels).view(-1, 1, 28, 28)\n",
    "        x = torch.cat([img, label_map], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# Train cGAN\n",
    "cG = ConditionalGenerator(latent_dim).to(device)\n",
    "cD = ConditionalDiscriminator().to(device)\n",
    "cG.apply(weights_init)\n",
    "cD.apply(weights_init)\n",
    "\n",
    "opt_G = torch.optim.Adam(cG.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "opt_D = torch.optim.Adam(cD.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(30):\n",
    "    for real_imgs, labels in train_loader:\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs, labels = real_imgs.to(device), labels.to(device)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        \n",
    "        # Train D\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = cG(z, labels).detach()\n",
    "        \n",
    "        d_loss = criterion(cD(real_imgs, labels), real_labels) + \\\n",
    "                 criterion(cD(fake_imgs, labels), fake_labels)\n",
    "        opt_D.zero_grad()\n",
    "        d_loss.backward()\n",
    "        opt_D.step()\n",
    "        \n",
    "        # Train G\n",
    "        z = torch.randn(batch_size, latent_dim).to(device)\n",
    "        fake_imgs = cG(z, labels)\n",
    "        g_loss = criterion(cD(fake_imgs, labels), real_labels)\n",
    "        opt_G.zero_grad()\n",
    "        g_loss.backward()\n",
    "        opt_G.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/30\")\n",
    "\n",
    "# Generate specific digits\n",
    "cG.eval()\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "with torch.no_grad():\n",
    "    for digit in range(10):\n",
    "        z = torch.randn(2, latent_dim).to(device)\n",
    "        labels = torch.tensor([digit, digit]).to(device)\n",
    "        imgs = (cG(z, labels) + 1) / 2\n",
    "        for row in range(2):\n",
    "            axes[row, digit].imshow(imgs[row].cpu().squeeze(), cmap='gray')\n",
    "            axes[row, digit].axis('off')\n",
    "        axes[0, digit].set_title(str(digit))\n",
    "plt.suptitle('Conditional GAN: Generating Specific Digits')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: Fashion-MNIST GAN\n",
    "fashion_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "fashion_data = datasets.FashionMNIST('./data', train=True, download=True, transform=fashion_transform)\n",
    "fashion_loader = DataLoader(fashion_data, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "fashion_G = DCGenerator(latent_dim).to(device)\n",
    "fashion_C = WCriticGP().to(device)\n",
    "fashion_G.apply(weights_init)\n",
    "\n",
    "print(\"Training WGAN-GP on Fashion-MNIST...\")\n",
    "fashion_history = train_wgan_gp(fashion_G, fashion_C, fashion_loader, epochs=30, latent_dim=latent_dim)\n",
    "\n",
    "print(\"\\nFashion-MNIST Generated Samples:\")\n",
    "show_samples(fashion_G, n=25, latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3: Training Stability Analysis\n",
    "# Compare loss variance as stability metric\n",
    "\n",
    "def compute_stability(history, key):\n",
    "    \"\"\"Compute rolling variance of loss.\"\"\"\n",
    "    losses = np.array(history[key])\n",
    "    # Rolling variance with window=10\n",
    "    window = 10\n",
    "    if len(losses) < window:\n",
    "        return np.var(losses)\n",
    "    variances = [np.var(losses[max(0,i-window):i+1]) for i in range(len(losses))]\n",
    "    return np.mean(variances[window:])\n",
    "\n",
    "print(\"Training Stability Analysis (lower = more stable):\")\n",
    "print(f\"DCGAN G-loss variance: {compute_stability(dc_history, 'g_loss'):.4f}\")\n",
    "print(f\"WGAN G-loss variance: {compute_stability(wgan_history, 'g_loss'):.4f}\")\n",
    "print(f\"WGAN-GP G-loss variance: {compute_stability(wgangp_history, 'g_loss'):.4f}\")\n",
    "\n",
    "# Plot losses\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "\n",
    "axes[0].plot(dc_history['g_loss'], label='G')\n",
    "axes[0].plot(dc_history['d_loss'], label='D')\n",
    "axes[0].set_title('DCGAN')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(wgan_history['g_loss'], label='G')\n",
    "axes[1].plot(wgan_history['c_loss'], label='C')\n",
    "axes[1].set_title('WGAN')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(wgangp_history['g_loss'], label='G')\n",
    "axes[2].plot(wgangp_history['c_loss'], label='C')\n",
    "axes[2].set_title('WGAN-GP')\n",
    "axes[2].legend()\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- DCGAN: Oscillating losses, potential instability\")\n",
    "print(\"- WGAN: Smoother but can plateau\")\n",
    "print(\"- WGAN-GP: Most stable training dynamics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
