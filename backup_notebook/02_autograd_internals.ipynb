{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.2: Autograd Internals\n",
    "\n",
    "Autograd is PyTorch's automatic differentiation engine. Understanding how it works under the hood is essential for:\n",
    "- Debugging gradient issues\n",
    "- Implementing custom operations\n",
    "- Optimizing memory usage during training\n",
    "- Understanding why certain code patterns work (or don't)\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand dynamic computation graphs and how they differ from static graphs\n",
    "- Master `requires_grad`, `grad_fn`, and the backward pass mechanics\n",
    "- Distinguish leaf tensors from intermediate tensors\n",
    "- Control gradient computation with `torch.no_grad()` and `detach()`\n",
    "- Implement custom autograd functions\n",
    "- Handle gradient accumulation correctly\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. The Computation Graph\n",
    "\n",
    "When you perform operations on tensors with `requires_grad=True`, PyTorch builds a **computation graph** that tracks how the output was computed. This graph is then used to compute gradients via backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dynamic vs Static Graphs\n",
    "\n",
    "| Feature | PyTorch (Dynamic) | TensorFlow 1.x (Static) |\n",
    "|---------|-------------------|-------------------------|\n",
    "| Graph creation | Every forward pass | Once, before training |\n",
    "| Control flow | Native Python if/for | Special graph ops |\n",
    "| Debugging | Standard Python debugger | Harder, separate execution |\n",
    "| Flexibility | Different graph each iteration | Same graph always |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d(x^2)/dx at x=2: 4.0\n",
      "d(x^3)/dx at x=2: 12.0\n"
     ]
    }
   ],
   "source": [
    "# Dynamic graph: different computation path each time\n",
    "def dynamic_example(x, use_square=True):\n",
    "    if use_square:  # Native Python control flow!\n",
    "        return x ** 2\n",
    "    else:\n",
    "        return x ** 3\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "\n",
    "# Different graphs created each call\n",
    "y1 = dynamic_example(x, use_square=True)\n",
    "y1.backward()\n",
    "print(f\"d(x^2)/dx at x=2: {x.grad.item()}\")  # 2*x = 4\n",
    "\n",
    "x.grad.zero_()  # Reset gradient\n",
    "\n",
    "y2 = dynamic_example(x, use_square=False)\n",
    "y2.backward()\n",
    "print(f\"d(x^3)/dx at x=2: {x.grad.item()}\")  # 3*x^2 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualizing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.grad_fn: None\n",
      "c.grad_fn: <MulBackward0 object at 0x7e8b17c0eec0>\n",
      "d.grad_fn: <AddBackward0 object at 0x7e8b17c0eec0>\n",
      "e.grad_fn: <SumBackward0 object at 0x7e8b17c0eec0>\n"
     ]
    }
   ],
   "source": [
    "# Every tensor knows how it was created via grad_fn\n",
    "a = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "c = a * b          # Multiplication\n",
    "d = c + a          # Addition\n",
    "e = d.sum()        # Sum (to get scalar for backward)\n",
    "\n",
    "print(f\"a.grad_fn: {a.grad_fn}\")  # None - it's a leaf\n",
    "print(f\"c.grad_fn: {c.grad_fn}\")  # MulBackward\n",
    "print(f\"d.grad_fn: {d.grad_fn}\")  # AddBackward\n",
    "print(f\"e.grad_fn: {e.grad_fn}\")  # SumBackward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation graph from e:\n",
      "e = <SumBackward0 object at 0x7e89c7370cd0>\n",
      "  └─ d = <AddBackward0 object at 0x7e89c7370cd0>\n",
      "      ├─ c = <MulBackward0 object at 0x7e89c7370cd0>\n",
      "      │   ├─ a (leaf)\n",
      "      │   └─ b (leaf)\n",
      "      └─ a (leaf)\n"
     ]
    }
   ],
   "source": [
    "# We can traverse the graph backwards\n",
    "def print_graph(tensor, indent=0):\n",
    "    \"\"\"Recursively print the computation graph.\"\"\"\n",
    "    prefix = \"  \" * indent\n",
    "    if tensor.grad_fn is not None:\n",
    "        print(f\"{prefix}{tensor.grad_fn}\")\n",
    "        for child, _ in tensor.grad_fn.next_functions:\n",
    "            if child is not None:\n",
    "                # child is a grad_fn, need to find its tensor\n",
    "                print(f\"{prefix}  └─ {child}\")\n",
    "    else:\n",
    "        print(f\"{prefix}Leaf tensor\")\n",
    "\n",
    "print(\"Computation graph from e:\")\n",
    "print(f\"e = {e.grad_fn}\")\n",
    "print(f\"  └─ d = {d.grad_fn}\")\n",
    "print(f\"      ├─ c = {c.grad_fn}\")\n",
    "print(f\"      │   ├─ a (leaf)\")\n",
    "print(f\"      │   └─ b (leaf)\")\n",
    "print(f\"      └─ a (leaf)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. requires_grad and Gradient Flow\n",
    "\n",
    "`requires_grad` is the switch that tells PyTorch whether to track operations for this tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default requires_grad: False\n",
      "Explicit requires_grad: True\n",
      "After requires_grad_(): True\n"
     ]
    }
   ],
   "source": [
    "# Default: requires_grad=False\n",
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(f\"Default requires_grad: {t1.requires_grad}\")\n",
    "\n",
    "# Explicitly enable\n",
    "t2 = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "print(f\"Explicit requires_grad: {t2.requires_grad}\")\n",
    "\n",
    "# Enable in-place (note the underscore)\n",
    "t1.requires_grad_(True)\n",
    "print(f\"After requires_grad_(): {t1.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a (grad=True) + b (grad=False) -> c.requires_grad: True\n",
      "d (no grad) + e (no grad) -> f.requires_grad: False\n"
     ]
    }
   ],
   "source": [
    "# Gradient flow rules:\n",
    "# If ANY input requires_grad, output requires_grad\n",
    "\n",
    "a = torch.tensor([1.0], requires_grad=True)\n",
    "b = torch.tensor([2.0], requires_grad=False)\n",
    "\n",
    "c = a + b\n",
    "print(f\"a (grad=True) + b (grad=False) -> c.requires_grad: {c.requires_grad}\")\n",
    "\n",
    "# All inputs no grad -> output no grad\n",
    "d = torch.tensor([1.0])\n",
    "e = torch.tensor([2.0])\n",
    "f = d + e\n",
    "print(f\"d (no grad) + e (no grad) -> f.requires_grad: {f.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Leaf Tensors vs Intermediate Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is leaf: True\n",
      "y is leaf: False\n",
      "z is leaf: False\n"
     ]
    }
   ],
   "source": [
    "# Leaf tensors: created directly by the user, not from operations\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "print(f\"x is leaf: {x.is_leaf}\")  # True\n",
    "\n",
    "# Intermediate tensors: results of operations\n",
    "y = x * 2\n",
    "print(f\"y is leaf: {y.is_leaf}\")  # False\n",
    "\n",
    "z = y.sum()\n",
    "print(f\"z is leaf: {z.is_leaf}\")  # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad (leaf): tensor([2., 2.])\n",
      "y.grad (non-leaf): None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7053/1812853869.py:9: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  print(f\"y.grad (non-leaf): {y.grad}\")  # None! Gradients not retained by default\n"
     ]
    }
   ],
   "source": [
    "# Important: Only leaf tensors have .grad populated after backward()\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x * 2\n",
    "z = y.sum()\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(f\"x.grad (leaf): {x.grad}\")      # Populated\n",
    "print(f\"y.grad (non-leaf): {y.grad}\")  # None! Gradients not retained by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad: tensor([2., 2.])\n",
      "y.grad (retained): tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# To retain gradients for non-leaf tensors, use retain_grad()\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x * 2\n",
    "y.retain_grad()  # Tell PyTorch to keep y's gradient\n",
    "z = y.sum()\n",
    "\n",
    "z.backward()\n",
    "\n",
    "print(f\"x.grad: {x.grad}\")\n",
    "print(f\"y.grad (retained): {y.grad}\")  # Now populated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. The Backward Pass\n",
    "\n",
    "When you call `.backward()`, PyTorch traverses the computation graph in reverse, computing gradients using the chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Basic Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 3.0\n",
      "y = x^2 = 9.0\n",
      "dy/dx = 2x = 6.0\n"
     ]
    }
   ],
   "source": [
    "# Simple example: y = x^2, dy/dx = 2x\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "y.backward()  # Computes dy/dx\n",
    "\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = x^2 = {y.item()}\")\n",
    "print(f\"dy/dx = 2x = {x.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autograd: -2.614574\n",
      "Manual:   -2.614574\n"
     ]
    }
   ],
   "source": [
    "# Chain rule in action: y = sin(x^2)\n",
    "# dy/dx = cos(x^2) * 2x\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = torch.sin(x ** 2)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# Manual calculation\n",
    "manual_grad = torch.cos(x ** 2) * 2 * x\n",
    "\n",
    "print(f\"Autograd: {x.grad.item():.6f}\")\n",
    "print(f\"Manual:   {manual_grad.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Backward with Non-Scalar Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: grad can be implicitly created only for scalar outputs\n"
     ]
    }
   ],
   "source": [
    "# backward() only works directly on scalars\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2  # Non-scalar output\n",
    "\n",
    "try:\n",
    "    y.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient via sum: tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Reduce to scalar\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "loss = y.sum()  # or y.mean()\n",
    "loss.backward()\n",
    "print(f\"Gradient via sum: {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with upstream [1,1,1]: tensor([2., 4., 6.])\n",
      "Gradient with upstream [1,0.5,0]: tensor([2., 2., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Solution 2: Provide gradient argument (Jacobian-vector product)\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "# gradient argument = \"upstream gradients\" (dL/dy for some loss L)\n",
    "# This computes dL/dx = dL/dy * dy/dx\n",
    "upstream = torch.tensor([1.0, 1.0, 1.0])  # Equivalent to .sum().backward()\n",
    "y.backward(gradient=upstream)\n",
    "print(f\"Gradient with upstream [1,1,1]: {x.grad}\")\n",
    "\n",
    "# Different upstream gradients\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "upstream = torch.tensor([1.0, 0.5, 0.0])  # Weight different elements\n",
    "y.backward(gradient=upstream)\n",
    "print(f\"Gradient with upstream [1,0.5,0]: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Multiple Backward Passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
     ]
    }
   ],
   "source": [
    "# By default, the graph is freed after backward()\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward()\n",
    "\n",
    "try:\n",
    "    y.backward()  # Graph already freed!\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First backward: tensor([4.])\n",
      "Second backward (accumulated): tensor([8.])\n",
      "After zero_(): tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "# Use retain_graph=True to keep the graph\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "y.backward(retain_graph=True)  # Keep the graph\n",
    "print(f\"First backward: {x.grad}\")\n",
    "\n",
    "# Note: gradients ACCUMULATE!\n",
    "y.backward(retain_graph=True)\n",
    "print(f\"Second backward (accumulated): {x.grad}\")\n",
    "\n",
    "x.grad.zero_()  # Reset\n",
    "y.backward()\n",
    "print(f\"After zero_(): {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Controlling Gradient Computation\n",
    "\n",
    "There are several ways to stop gradient tracking, each with different use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: y.requires_grad = True\n",
      "In no_grad: z.requires_grad = False\n",
      "After no_grad: w.requires_grad = True\n"
     ]
    }
   ],
   "source": [
    "# torch.no_grad() temporarily disables gradient tracking\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# Normal operation - gradient tracked\n",
    "y = x * 2\n",
    "print(f\"Normal: y.requires_grad = {y.requires_grad}\")\n",
    "\n",
    "# Inside no_grad context - no tracking\n",
    "with torch.no_grad():\n",
    "    z = x * 2\n",
    "    print(f\"In no_grad: z.requires_grad = {z.requires_grad}\")\n",
    "\n",
    "# Back to normal\n",
    "w = x * 2\n",
    "print(f\"After no_grad: w.requires_grad = {w.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: y.requires_grad = True\n",
      "Inference: y.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "# Common use case: Inference/evaluation\n",
    "model = nn.Linear(10, 5)\n",
    "x = torch.randn(3, 10)\n",
    "\n",
    "# Training mode - need gradients\n",
    "model.train()\n",
    "y_train = model(x)\n",
    "print(f\"Training: y.requires_grad = {y_train.requires_grad}\")\n",
    "\n",
    "# Inference mode - no gradients needed (faster, less memory)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_eval = model(x)\n",
    "    print(f\"Inference: y.requires_grad = {y_eval.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 torch.inference_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In inference_mode: y.requires_grad = False\n"
     ]
    }
   ],
   "source": [
    "# inference_mode is like no_grad but faster (PyTorch 1.9+)\n",
    "# It provides additional optimizations by guaranteeing no gradient computation\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y = x * 2\n",
    "    print(f\"In inference_mode: y.requires_grad = {y.requires_grad}\")\n",
    "    \n",
    "# Prefer inference_mode() over no_grad() for pure inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.requires_grad: True\n",
      "y_detached.requires_grad: False\n",
      "Share memory: True\n"
     ]
    }
   ],
   "source": [
    "# detach() creates a tensor that shares data but doesn't track gradients\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "\n",
    "y_detached = y.detach()\n",
    "\n",
    "print(f\"y.requires_grad: {y.requires_grad}\")\n",
    "print(f\"y_detached.requires_grad: {y_detached.requires_grad}\")\n",
    "print(f\"Share memory: {y.data_ptr() == y_detached.data_ptr()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder grad: None\n",
      "Decoder grad exists: True\n"
     ]
    }
   ],
   "source": [
    "# Use case: Breaking the computation graph\n",
    "# Example: Training with a frozen encoder\n",
    "\n",
    "class FrozenEncoderModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(10, 20)  # Pretrained, frozen\n",
    "        self.decoder = nn.Linear(20, 5)   # Trainable\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Detach encoder output - gradients won't flow to encoder\n",
    "        encoded = self.encoder(x).detach()\n",
    "        return self.decoder(encoded)\n",
    "\n",
    "model = FrozenEncoderModel()\n",
    "x = torch.randn(3, 10)\n",
    "y = model(x)\n",
    "loss = y.sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Encoder grad: {model.encoder.weight.grad}\")  # None - detached\n",
    "print(f\"Decoder grad exists: {model.decoder.weight.grad is not None}\")  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detach shares memory: True\n",
      "clone().detach() shares memory: False\n"
     ]
    }
   ],
   "source": [
    "# detach() vs clone().detach()\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "# detach() shares memory - modifying one affects the other\n",
    "y_detach = y.detach()\n",
    "\n",
    "# clone().detach() creates independent copy\n",
    "y_clone_detach = y.clone().detach()\n",
    "\n",
    "print(f\"detach shares memory: {y.data_ptr() == y_detach.data_ptr()}\")\n",
    "print(f\"clone().detach() shares memory: {y.data_ptr() == y_clone_detach.data_ptr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Gradient Accumulation\n",
    "\n",
    "PyTorch accumulates gradients by default. This is a feature, not a bug!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backward 1: x.grad = tensor([2.])\n",
      "After backward 2: x.grad = tensor([4.])\n",
      "After backward 3: x.grad = tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "# Gradients accumulate across backward calls\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "for i in range(3):\n",
    "    y = x ** 2\n",
    "    y.backward()\n",
    "    print(f\"After backward {i+1}: x.grad = {x.grad}\")\n",
    "\n",
    "# Without zeroing, gradients add up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: x.grad = tensor([2.])\n",
      "Iteration 2: x.grad = tensor([2.])\n",
      "Iteration 3: x.grad = tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# Standard training loop pattern: zero gradients before backward\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "for i in range(3):\n",
    "    if x.grad is not None:\n",
    "        x.grad.zero_()  # Reset gradient\n",
    "    \n",
    "    y = x ** 2\n",
    "    y.backward()\n",
    "    print(f\"Iteration {i+1}: x.grad = {x.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: weight grad norm = 10.9329\n",
      "Iteration 2: weight grad norm = 7.4428\n",
      "Iteration 3: weight grad norm = 9.8701\n"
     ]
    }
   ],
   "source": [
    "# For optimizers, use optimizer.zero_grad()\n",
    "model = nn.Linear(10, 5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(3):\n",
    "    optimizer.zero_grad()  # Reset all parameter gradients\n",
    "    \n",
    "    x = torch.randn(3, 10)\n",
    "    y = model(x)\n",
    "    loss = y.sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()  # Update parameters\n",
    "    \n",
    "    print(f\"Iteration {i+1}: weight grad norm = {model.weight.grad.norm():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 When Gradient Accumulation is Useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Use case: Simulating larger batch sizes with limited memory\n",
    "model = nn.Linear(100, 10)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# We want effective batch size of 32, but can only fit 8 in memory\n",
    "accumulation_steps = 4\n",
    "micro_batch_size = 8\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "for i in range(accumulation_steps):\n",
    "    x = torch.randn(micro_batch_size, 100)\n",
    "    y = model(x)\n",
    "    loss = y.sum() / accumulation_steps  # Scale loss\n",
    "    loss.backward()  # Gradients accumulate\n",
    "\n",
    "optimizer.step()  # Single update with accumulated gradients\n",
    "\n",
    "print(f\"Effective batch size: {micro_batch_size * accumulation_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Custom Autograd Functions\n",
    "\n",
    "You can define custom operations with custom forward and backward passes using `torch.autograd.Function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:    [-2.0, -1.0, 0.0, 1.0, 2.0]\n",
      "Output:   [0.0, 0.0, 0.0, 1.0, 2.0]\n",
      "Gradient: [0.0, 0.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Example: Custom ReLU implementation\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        ctx is a context object to save tensors for backward.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(x)  # Save input for backward\n",
    "        return x.clamp(min=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Backward pass.\n",
    "        grad_output is the gradient of the loss w.r.t. the output.\n",
    "        Returns gradient w.r.t. input.\n",
    "        \"\"\"\n",
    "        x, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[x < 0] = 0  # Gradient is 0 where x < 0\n",
    "        return grad_input\n",
    "\n",
    "# Use it\n",
    "x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0], requires_grad=True)\n",
    "y = MyReLU.apply(x)  # Use .apply(), not direct call\n",
    "y.sum().backward()\n",
    "\n",
    "print(f\"Input:    {x.tolist()}\")\n",
    "print(f\"Output:   {y.tolist()}\")\n",
    "print(f\"Gradient: {x.grad.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:    [0.30000001192092896, 0.699999988079071, 1.399999976158142, 2.5999999046325684]\n",
      "Rounded:  [0.0, 1.0, 1.0, 3.0]\n",
      "Gradient: [-4.0, -2.0, -2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# More complex example: Straight-through estimator (STE)\n",
    "# Used for quantization - forward uses discrete values, backward pretends it's identity\n",
    "\n",
    "class StraightThroughEstimator(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        # Forward: round to nearest integer\n",
    "        return torch.round(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward: pretend rounding didn't happen (identity gradient)\n",
    "        return grad_output\n",
    "\n",
    "x = torch.tensor([0.3, 0.7, 1.4, 2.6], requires_grad=True)\n",
    "y = StraightThroughEstimator.apply(x)\n",
    "loss = (y - 2).pow(2).sum()\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Input:    {x.tolist()}\")\n",
    "print(f\"Rounded:  {y.tolist()}\")\n",
    "print(f\"Gradient: {x.grad.tolist()}\")  # Gradients flow through!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad: tensor([0.7000, 0.7000])\n",
      "y.grad: tensor([0.3000, 0.3000])\n"
     ]
    }
   ],
   "source": [
    "# Example with multiple inputs and outputs\n",
    "class WeightedSum(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, y, weight):\n",
    "        ctx.save_for_backward(x, y)\n",
    "        ctx.weight = weight  # Save non-tensor data\n",
    "        return weight * x + (1 - weight) * y\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, y = ctx.saved_tensors\n",
    "        weight = ctx.weight\n",
    "        \n",
    "        # Return gradient for each input\n",
    "        grad_x = grad_output * weight\n",
    "        grad_y = grad_output * (1 - weight)\n",
    "        grad_weight = None  # weight doesn't require grad (it's a float)\n",
    "        \n",
    "        return grad_x, grad_y, grad_weight\n",
    "\n",
    "x = torch.tensor([1.0, 2.0], requires_grad=True)\n",
    "y = torch.tensor([3.0, 4.0], requires_grad=True)\n",
    "z = WeightedSum.apply(x, y, 0.7)\n",
    "z.sum().backward()\n",
    "\n",
    "print(f\"x.grad: {x.grad}\")  # Should be 0.7\n",
    "print(f\"y.grad: {y.grad}\")  # Should be 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyReLU gradient check passed: True\n"
     ]
    }
   ],
   "source": [
    "# Verify your custom gradients with numerical gradients\n",
    "from torch.autograd import gradcheck\n",
    "\n",
    "# Test MyReLU\n",
    "# gradcheck requires double precision for numerical stability\n",
    "x = torch.randn(5, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "# gradcheck compares analytical gradient with numerical finite difference\n",
    "result = gradcheck(MyReLU.apply, x, eps=1e-6, atol=1e-4, rtol=1e-3)\n",
    "print(f\"MyReLU gradient check passed: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Debugging Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Detecting Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7e89b984ed50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable anomaly detection to find the source of NaN/Inf gradients\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "x = torch.tensor([0.0], requires_grad=True)\n",
    "\n",
    "try:\n",
    "    y = torch.log(x)  # log(0) = -inf\n",
    "    y.backward()      # Will produce NaN gradient\n",
    "except RuntimeError as e:\n",
    "    print(f\"Caught anomaly: {str(e)[:100]}...\")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)  # Disable (it's slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Using Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward pass:\n",
      "y grad: tensor([3.])\n",
      "x grad: tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "# Register hooks to inspect gradients during backward\n",
    "def print_grad_hook(name):\n",
    "    def hook(grad):\n",
    "        print(f\"{name} grad: {grad}\")\n",
    "        return grad  # Can modify gradient here\n",
    "    return hook\n",
    "\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x ** 2\n",
    "z = y * 3\n",
    "\n",
    "# Register hooks\n",
    "x.register_hook(print_grad_hook(\"x\"))\n",
    "y.register_hook(print_grad_hook(\"y\"))\n",
    "\n",
    "print(\"Backward pass:\")\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipped gradient: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# Use hooks to clip gradients\n",
    "def clip_grad_hook(max_norm):\n",
    "    def hook(grad):\n",
    "        norm = grad.norm()\n",
    "        if norm > max_norm:\n",
    "            return grad * max_norm / norm\n",
    "        return grad\n",
    "    return hook\n",
    "\n",
    "x = torch.tensor([10.0], requires_grad=True)\n",
    "x.register_hook(clip_grad_hook(max_norm=1.0))\n",
    "\n",
    "y = x ** 2  # Gradient would be 20, but we clip to 1\n",
    "y.backward()\n",
    "\n",
    "print(f\"Clipped gradient: {x.grad}\")  # 1.0, not 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Manual Gradient Computation\n",
    "\n",
    "Compute the gradient of $f(x) = \\frac{1}{1 + e^{-x}}$ (sigmoid) manually and verify with autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    Compute d/dx sigmoid(x).\n",
    "    Hint: sigmoid'(x) = sigmoid(x) * (1 - sigmoid(x))\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "x = torch.tensor([0.0, 1.0, -1.0, 2.0], requires_grad=True)\n",
    "\n",
    "# Autograd\n",
    "y = sigmoid(x)\n",
    "y.sum().backward()\n",
    "autograd_grad = x.grad.clone()\n",
    "\n",
    "# Manual\n",
    "# manual_grad = sigmoid_derivative(x.detach())\n",
    "\n",
    "# print(f\"Autograd: {autograd_grad}\")\n",
    "# print(f\"Manual:   {manual_grad}\")\n",
    "# print(f\"Match: {torch.allclose(autograd_grad, manual_grad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Implement Custom Softmax Backward\n",
    "\n",
    "Implement a custom autograd function for softmax with its correct backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySoftmax(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        \"\"\"\n",
    "        Compute softmax along the last dimension.\n",
    "        softmax(x)_i = exp(x_i) / sum_j(exp(x_j))\n",
    "        \"\"\"\n",
    "        # For numerical stability, subtract max\n",
    "        x_max = x.max(dim=-1, keepdim=True).values\n",
    "        exp_x = torch.exp(x - x_max)\n",
    "        softmax = exp_x / exp_x.sum(dim=-1, keepdim=True)\n",
    "        ctx.save_for_backward(softmax)\n",
    "        return softmax\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        Compute gradient of softmax.\n",
    "        Let s = softmax(x), then:\n",
    "        ds_i/dx_j = s_i * (delta_ij - s_j)\n",
    "        where delta_ij is 1 if i==j, 0 otherwise.\n",
    "        \n",
    "        For the chain rule with upstream gradient g:\n",
    "        dx_j = sum_i(g_i * ds_i/dx_j) = sum_i(g_i * s_i * (delta_ij - s_j))\n",
    "             = g_j * s_j - s_j * sum_i(g_i * s_i)\n",
    "             = s_j * (g_j - sum_i(g_i * s_i))\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "# Test\n",
    "x = torch.randn(3, 4, dtype=torch.double, requires_grad=True)\n",
    "\n",
    "# Verify with gradcheck\n",
    "# result = gradcheck(MySoftmax.apply, x, eps=1e-6, atol=1e-4, rtol=1e-3)\n",
    "# print(f\"Gradient check passed: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Build a Mini Autograd System\n",
    "\n",
    "Implement a simplified autograd system from scratch to understand how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\"A simple scalar value with automatic differentiation.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, children=(), op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        self._children = set(children)\n",
    "        self._op = op\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data:.4f}, grad={self.grad:.4f})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "        \n",
    "        def _backward():\n",
    "            # d(a+b)/da = 1, d(a+b)/db = 1\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "        \n",
    "        def _backward():\n",
    "            # d(a*b)/da = b, d(a*b)/db = a\n",
    "            # YOUR CODE HERE\n",
    "            pass\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def __pow__(self, n):\n",
    "        out = Value(self.data ** n, (self,), f'**{n}')\n",
    "        \n",
    "        def _backward():\n",
    "            # d(x^n)/dx = n * x^(n-1)\n",
    "            # YOUR CODE HERE\n",
    "            pass\n",
    "        out._backward = _backward\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        \"\"\"Topological sort and backprop.\"\"\"\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        \n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._children:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        \n",
    "        build_topo(self)\n",
    "        \n",
    "        self.grad = 1.0\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "# Test when implemented:\n",
    "# x = Value(2.0)\n",
    "# y = Value(3.0)\n",
    "# z = x * y + x ** 2\n",
    "# z.backward()\n",
    "# print(f\"x: {x}\")  # grad should be y + 2x = 3 + 4 = 7\n",
    "# print(f\"y: {y}\")  # grad should be x = 2\n",
    "# print(f\"z: {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1 Solution:\n",
      "Autograd: tensor([0.2500, 0.1966, 0.1966, 0.1050])\n",
      "Manual:   tensor([0.2500, 0.1966, 0.1966, 0.1050])\n",
      "Match: True\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1 Solution\n",
    "def sigmoid_derivative_solution(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "x = torch.tensor([0.0, 1.0, -1.0, 2.0], requires_grad=True)\n",
    "y = sigmoid(x)\n",
    "y.sum().backward()\n",
    "\n",
    "autograd_grad = x.grad.clone()\n",
    "manual_grad = sigmoid_derivative_solution(x.detach())\n",
    "\n",
    "print(\"Exercise 1 Solution:\")\n",
    "print(f\"Autograd: {autograd_grad}\")\n",
    "print(f\"Manual:   {manual_grad}\")\n",
    "print(f\"Match: {torch.allclose(autograd_grad, manual_grad)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 2 Solution:\n",
      "Gradient check passed: True\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2 Solution\n",
    "class MySoftmaxSolution(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        x_max = x.max(dim=-1, keepdim=True).values\n",
    "        exp_x = torch.exp(x - x_max)\n",
    "        softmax = exp_x / exp_x.sum(dim=-1, keepdim=True)\n",
    "        ctx.save_for_backward(softmax)\n",
    "        return softmax\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        softmax, = ctx.saved_tensors\n",
    "        # dx_j = s_j * (g_j - sum_i(g_i * s_i))\n",
    "        dot_product = (grad_output * softmax).sum(dim=-1, keepdim=True)\n",
    "        return softmax * (grad_output - dot_product)\n",
    "\n",
    "x = torch.randn(3, 4, dtype=torch.double, requires_grad=True)\n",
    "result = gradcheck(MySoftmaxSolution.apply, x, eps=1e-6, atol=1e-4, rtol=1e-3)\n",
    "print(f\"\\nExercise 2 Solution:\")\n",
    "print(f\"Gradient check passed: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exercise 3 Solution:\n",
      "x: Value(data=2.0000, grad=7.0000)\n",
      "y: Value(data=3.0000, grad=2.0000)\n",
      "z: Value(data=10.0000, grad=1.0000)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3 Solution\n",
    "class ValueSolution:\n",
    "    def __init__(self, data, children=(), op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._backward = lambda: None\n",
    "        self._children = set(children)\n",
    "        self._op = op\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data:.4f}, grad={self.grad:.4f})\"\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, ValueSolution) else ValueSolution(other)\n",
    "        out = ValueSolution(self.data + other.data, (self, other), '+')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, ValueSolution) else ValueSolution(other)\n",
    "        out = ValueSolution(self.data * other.data, (self, other), '*')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def __pow__(self, n):\n",
    "        out = ValueSolution(self.data ** n, (self,), f'**{n}')\n",
    "        \n",
    "        def _backward():\n",
    "            self.grad += n * (self.data ** (n - 1)) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "    \n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        \n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._children:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        \n",
    "        build_topo(self)\n",
    "        self.grad = 1.0\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "print(\"\\nExercise 3 Solution:\")\n",
    "x = ValueSolution(2.0)\n",
    "y = ValueSolution(3.0)\n",
    "z = x * y + x ** 2  # z = xy + x^2, dz/dx = y + 2x = 7, dz/dy = x = 2\n",
    "z.backward()\n",
    "\n",
    "print(f\"x: {x}\")  # grad = 7\n",
    "print(f\"y: {y}\")  # grad = 2\n",
    "print(f\"z: {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Key takeaways from this notebook:\n",
    "\n",
    "1. **Dynamic Graphs**: PyTorch builds computation graphs on-the-fly, enabling native Python control flow\n",
    "2. **requires_grad**: The switch that enables gradient tracking\n",
    "3. **Leaf vs Intermediate**: Only leaf tensors retain gradients by default\n",
    "4. **backward()**: Computes gradients by traversing the graph in reverse\n",
    "5. **Gradient Control**: Use `no_grad()`, `inference_mode()`, and `detach()` appropriately\n",
    "6. **Gradient Accumulation**: Gradients add up; zero them before each optimization step\n",
    "7. **Custom Functions**: Use `torch.autograd.Function` for custom forward/backward passes\n",
    "\n",
    "---\n",
    "*Next: Module 1.3 - nn.Module Architecture*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
