{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - Modern Computer Vision: Transfer Learning, Detection, and Segmentation\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Master transfer learning** - Using pretrained models, fine-tuning strategies, feature extraction\n",
    "2. **Understand object detection** - Region proposals, anchor boxes, YOLO concepts\n",
    "3. **Implement semantic segmentation** - FCN, U-Net architecture, pixel-wise classification\n",
    "4. **Use torchvision models** - Leveraging the model zoo for various CV tasks\n",
    "5. **Apply modern techniques** - Data augmentation, test-time augmentation, model ensembling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "from torchvision.datasets import CIFAR10, VOCSegmentation\n",
    "from torchvision.models import resnet18, resnet50, ResNet18_Weights, ResNet50_Weights\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "import os\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Transfer Learning\n",
    "\n",
    "Transfer learning uses knowledge from a model trained on a large dataset (like ImageNet) and applies it to a new task. This works because early layers learn general features (edges, textures) that transfer well.\n",
    "\n",
    "### 1.1 Loading Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern way to load pretrained models (PyTorch 2.0+)\n",
    "\n",
    "# Load ResNet-18 with ImageNet weights\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Inspect the architecture\n",
    "print(\"ResNet-18 Architecture:\")\n",
    "print(f\"  Input: 3 channels (RGB)\")\n",
    "print(f\"  conv1: {model.conv1}\")\n",
    "print(f\"  fc (classifier): {model.fc}\")\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the preprocessing transforms for the model\n",
    "weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "print(\"Preprocessing transforms:\")\n",
    "print(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample image\n",
    "\n",
    "def load_image_from_url(url: str) -> Image.Image:\n",
    "    \"\"\"Load an image from URL\"\"\"\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "\n",
    "# Load a sample image (using a public domain image)\n",
    "sample_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "\n",
    "try:\n",
    "    img = load_image_from_url(sample_url)\n",
    "    \n",
    "    # Preprocess and predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = preprocess(img).unsqueeze(0)\n",
    "        output = model(x)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "    \n",
    "    # Get top 5 predictions\n",
    "    categories = weights.meta[\"categories\"]\n",
    "    top5_probs, top5_idx = probs[0].topk(5)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Input Image')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    y_pos = range(5)\n",
    "    plt.barh(y_pos, top5_probs.numpy())\n",
    "    plt.yticks(y_pos, [categories[i] for i in top5_idx])\n",
    "    plt.xlabel('Probability')\n",
    "    plt.title('Top 5 Predictions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not load image: {e}\")\n",
    "    print(\"Skipping visualization...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transfer Learning Strategies\n",
    "\n",
    "There are three main strategies:\n",
    "\n",
    "1. **Feature Extraction**: Freeze all pretrained layers, only train new classifier\n",
    "2. **Fine-tuning (Full)**: Train all layers with a small learning rate\n",
    "3. **Fine-tuning (Gradual)**: Freeze early layers, train later layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Feature Extraction\n",
    "\n",
    "def create_feature_extractor(num_classes: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Create a model for feature extraction.\n",
    "    Freezes all pretrained weights, only trains the classifier.\n",
    "    \"\"\"\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Freeze all layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace classifier\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    # Count trainable parameters\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable:,} / {total:,} ({100*trainable/total:.1f}%)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model_fe = create_feature_extractor(num_classes=10)\n",
    "print(f\"New classifier: {model_fe.fc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 2: Full Fine-tuning\n",
    "\n",
    "def create_finetuned_model(num_classes: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Create a model for full fine-tuning.\n",
    "    All layers are trainable, use smaller learning rate for pretrained layers.\n",
    "    \"\"\"\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    \n",
    "    # Replace classifier\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    # All parameters trainable\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"All parameters trainable: {trainable:,}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_param_groups(model, lr_backbone=1e-4, lr_head=1e-3):\n",
    "    \"\"\"\n",
    "    Create parameter groups with different learning rates.\n",
    "    Backbone (pretrained): smaller LR\n",
    "    Head (new): larger LR\n",
    "    \"\"\"\n",
    "    backbone_params = []\n",
    "    head_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc' in name:\n",
    "            head_params.append(param)\n",
    "        else:\n",
    "            backbone_params.append(param)\n",
    "    \n",
    "    return [\n",
    "        {'params': backbone_params, 'lr': lr_backbone},\n",
    "        {'params': head_params, 'lr': lr_head}\n",
    "    ]\n",
    "\n",
    "\n",
    "model_ft = create_finetuned_model(num_classes=10)\n",
    "param_groups = get_param_groups(model_ft)\n",
    "print(f\"Backbone params: {len(param_groups[0]['params'])} tensors, LR={param_groups[0]['lr']}\")\n",
    "print(f\"Head params: {len(param_groups[1]['params'])} tensors, LR={param_groups[1]['lr']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 3: Gradual Unfreezing\n",
    "\n",
    "class GradualUnfreezer:\n",
    "    \"\"\"\n",
    "    Gradually unfreeze layers during training.\n",
    "    Start with only classifier trainable, then unfreeze deeper layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, layer_groups: List[str]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model: PyTorch model\n",
    "            layer_groups: List of layer name prefixes to unfreeze in order\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.layer_groups = layer_groups\n",
    "        self.current_group = -1\n",
    "        \n",
    "        # Initially freeze all except classifier\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    def unfreeze_next(self):\n",
    "        \"\"\"Unfreeze the next layer group\"\"\"\n",
    "        self.current_group += 1\n",
    "        \n",
    "        if self.current_group >= len(self.layer_groups):\n",
    "            print(\"All layers already unfrozen\")\n",
    "            return\n",
    "        \n",
    "        group_name = self.layer_groups[self.current_group]\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name.startswith(group_name):\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        trainable = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"Unfroze {group_name}, trainable params: {trainable:,}\")\n",
    "\n",
    "\n",
    "# Example usage with ResNet\n",
    "model_gradual = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model_gradual.fc = nn.Linear(model_gradual.fc.in_features, 10)\n",
    "\n",
    "# Define layer groups (from last to first)\n",
    "layer_groups = ['layer4', 'layer3', 'layer2', 'layer1', 'conv1']\n",
    "unfreezer = GradualUnfreezer(model_gradual, layer_groups)\n",
    "\n",
    "print(\"Initial state:\")\n",
    "print(f\"Trainable: {sum(p.numel() for p in model_gradual.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "print(\"\\nUnfreezing layers:\")\n",
    "for _ in range(3):\n",
    "    unfreezer.unfreeze_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Training with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare CIFAR-10 for transfer learning\n",
    "\n",
    "# CIFAR-10 images are 32x32, ResNet expects 224x224\n",
    "train_transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = CIFAR10('../data', train=True, download=True, transform=train_transform)\n",
    "test_dataset = CIFAR10('../data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "# Use smaller subset for faster training\n",
    "train_subset, _ = random_split(train_dataset, [5000, 45000])\n",
    "test_subset, _ = random_split(test_dataset, [1000, 9000])\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Training samples: {len(train_subset)}\")\n",
    "print(f\"Test samples: {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with feature extraction\n",
    "\n",
    "model = create_feature_extractor(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
    "\n",
    "print(\"Training with Feature Extraction (frozen backbone):\")\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.1f}% | Test Acc: {test_acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune with different learning rates\n",
    "\n",
    "model = create_finetuned_model(num_classes=10).to(device)\n",
    "param_groups = get_param_groups(model, lr_backbone=1e-5, lr_head=1e-3)\n",
    "optimizer = torch.optim.Adam(param_groups)\n",
    "\n",
    "print(\"\\nTraining with Full Fine-tuning (differential LR):\")\n",
    "for epoch in range(5):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.1f}% | Test Acc: {test_acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Object Detection\n",
    "\n",
    "Object detection finds and classifies multiple objects in an image. Key concepts:\n",
    "\n",
    "- **Bounding boxes**: (x, y, width, height) or (x1, y1, x2, y2)\n",
    "- **IoU (Intersection over Union)**: Measures overlap between boxes\n",
    "- **Anchor boxes**: Predefined box shapes the model refines\n",
    "- **Non-max suppression**: Removes duplicate detections\n",
    "\n",
    "### 2.1 Understanding Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1: torch.Tensor, box2: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two boxes.\n",
    "    \n",
    "    Args:\n",
    "        box1, box2: Tensors of shape (4,) with [x1, y1, x2, y2]\n",
    "    \n",
    "    Returns:\n",
    "        IoU value between 0 and 1\n",
    "    \"\"\"\n",
    "    # Calculate intersection\n",
    "    x1 = torch.max(box1[0], box2[0])\n",
    "    y1 = torch.max(box1[1], box2[1])\n",
    "    x2 = torch.min(box1[2], box2[2])\n",
    "    y2 = torch.min(box1[3], box2[3])\n",
    "    \n",
    "    intersection = torch.clamp(x2 - x1, min=0) * torch.clamp(y2 - y1, min=0)\n",
    "    \n",
    "    # Calculate union\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / (union + 1e-6)\n",
    "\n",
    "\n",
    "def visualize_iou():\n",
    "    \"\"\"Visualize IoU between two boxes\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    test_cases = [\n",
    "        (torch.tensor([10, 10, 50, 50]), torch.tensor([30, 30, 70, 70])),  # Partial overlap\n",
    "        (torch.tensor([10, 10, 50, 50]), torch.tensor([60, 60, 100, 100])),  # No overlap\n",
    "        (torch.tensor([10, 10, 50, 50]), torch.tensor([15, 15, 45, 45])),  # High overlap\n",
    "    ]\n",
    "    \n",
    "    for ax, (box1, box2) in zip(axes, test_cases):\n",
    "        iou = calculate_iou(box1, box2).item()\n",
    "        \n",
    "        # Draw boxes\n",
    "        from matplotlib.patches import Rectangle\n",
    "        ax.add_patch(Rectangle((box1[0], box1[1]), box1[2]-box1[0], box1[3]-box1[1],\n",
    "                               fill=False, edgecolor='blue', linewidth=2, label='Box 1'))\n",
    "        ax.add_patch(Rectangle((box2[0], box2[1]), box2[2]-box2[0], box2[3]-box2[1],\n",
    "                               fill=False, edgecolor='red', linewidth=2, label='Box 2'))\n",
    "        ax.set_xlim(0, 110)\n",
    "        ax.set_ylim(0, 110)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(f'IoU = {iou:.3f}')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_iou()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Non-Maximum Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(boxes: torch.Tensor, scores: torch.Tensor, iou_threshold: float = 0.5) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Non-Maximum Suppression to remove duplicate detections.\n",
    "    \n",
    "    Args:\n",
    "        boxes: (N, 4) tensor of boxes [x1, y1, x2, y2]\n",
    "        scores: (N,) tensor of confidence scores\n",
    "        iou_threshold: Boxes with IoU > threshold are suppressed\n",
    "    \n",
    "    Returns:\n",
    "        Indices of boxes to keep\n",
    "    \"\"\"\n",
    "    # Sort by score (descending)\n",
    "    order = scores.argsort(descending=True)\n",
    "    \n",
    "    keep = []\n",
    "    while order.numel() > 0:\n",
    "        # Keep highest scoring box\n",
    "        i = order[0].item()\n",
    "        keep.append(i)\n",
    "        \n",
    "        if order.numel() == 1:\n",
    "            break\n",
    "        \n",
    "        # Calculate IoU with remaining boxes\n",
    "        remaining = order[1:]\n",
    "        ious = torch.tensor([calculate_iou(boxes[i], boxes[j]) for j in remaining])\n",
    "        \n",
    "        # Keep boxes with IoU below threshold\n",
    "        mask = ious <= iou_threshold\n",
    "        order = remaining[mask]\n",
    "    \n",
    "    return torch.tensor(keep)\n",
    "\n",
    "\n",
    "# Example\n",
    "boxes = torch.tensor([\n",
    "    [10, 10, 50, 50],\n",
    "    [12, 12, 52, 52],  # Almost same as box 0\n",
    "    [100, 100, 150, 150],\n",
    "    [102, 102, 152, 152],  # Almost same as box 2\n",
    "], dtype=torch.float32)\n",
    "\n",
    "scores = torch.tensor([0.9, 0.8, 0.95, 0.85])\n",
    "\n",
    "keep_indices = nms(boxes, scores, iou_threshold=0.5)\n",
    "print(f\"Original boxes: {len(boxes)}\")\n",
    "print(f\"After NMS: {len(keep_indices)}\")\n",
    "print(f\"Kept indices: {keep_indices.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Using Pretrained Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Faster R-CNN pretrained on COCO\n",
    "\n",
    "detection_model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "detection_model.eval()\n",
    "detection_model.to(device)\n",
    "\n",
    "# COCO class names\n",
    "COCO_CLASSES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "print(f\"Faster R-CNN loaded with {len(COCO_CLASSES)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(model, image: Image.Image, threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    Run object detection on an image.\n",
    "    \n",
    "    Returns:\n",
    "        boxes, labels, scores\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Detect\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor)\n",
    "    \n",
    "    pred = predictions[0]\n",
    "    \n",
    "    # Filter by confidence\n",
    "    mask = pred['scores'] > threshold\n",
    "    boxes = pred['boxes'][mask].cpu()\n",
    "    labels = pred['labels'][mask].cpu()\n",
    "    scores = pred['scores'][mask].cpu()\n",
    "    \n",
    "    return boxes, labels, scores\n",
    "\n",
    "\n",
    "def visualize_detections(image: Image.Image, boxes, labels, scores, classes):\n",
    "    \"\"\"Visualize detection results\"\"\"\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, len(classes)))\n",
    "    \n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        color = colors[label % len(colors)]\n",
    "        \n",
    "        # Draw box\n",
    "        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,\n",
    "                            fill=False, edgecolor=color, linewidth=2)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Draw label\n",
    "        class_name = classes[label] if label < len(classes) else f'class_{label}'\n",
    "        ax.text(x1, y1-5, f'{class_name}: {score:.2f}',\n",
    "               color='white', fontsize=10,\n",
    "               bbox=dict(boxstyle='round', facecolor=color, alpha=0.8))\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Test detection on sample image\n",
    "try:\n",
    "    img = load_image_from_url(sample_url)\n",
    "    boxes, labels, scores = detect_objects(detection_model, img)\n",
    "    print(f\"Detected {len(boxes)} objects\")\n",
    "    visualize_detections(img, boxes, labels, scores, COCO_CLASSES)\n",
    "except Exception as e:\n",
    "    print(f\"Could not run detection: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Simple YOLO-style Detection Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDetectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified YOLO-style detection head.\n",
    "    \n",
    "    Divides image into SxS grid cells.\n",
    "    Each cell predicts B bounding boxes with confidence and C class probabilities.\n",
    "    \n",
    "    Output per cell: B * (5 + C) values\n",
    "        - 5 = (x, y, w, h, confidence)\n",
    "        - C = class probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, num_classes: int = 20, \n",
    "                 grid_size: int = 7, num_boxes: int = 2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.S = grid_size\n",
    "        self.B = num_boxes\n",
    "        self.C = num_classes\n",
    "        \n",
    "        # Output channels: B * 5 (box params) + C (class probs)\n",
    "        out_channels = self.B * 5 + self.C\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1024, 3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(1024, out_channels, 1),\n",
    "        )\n",
    "        \n",
    "        # Adaptive pool to get SxS grid\n",
    "        self.pool = nn.AdaptiveAvgPool2d(grid_size)\n",
    "    \n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: (batch, channels, H, W) from backbone\n",
    "        \n",
    "        Returns:\n",
    "            (batch, S, S, B*5 + C) predictions\n",
    "        \"\"\"\n",
    "        x = self.conv(features)\n",
    "        x = self.pool(x)\n",
    "        # Reshape to (batch, S, S, B*5 + C)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Test\n",
    "backbone = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "# Remove classifier, use as feature extractor\n",
    "backbone = nn.Sequential(*list(backbone.children())[:-2])\n",
    "\n",
    "detection_head = SimpleDetectionHead(in_channels=512, num_classes=20)\n",
    "\n",
    "x = torch.randn(4, 3, 448, 448)\n",
    "features = backbone(x)\n",
    "print(f\"Backbone output: {features.shape}\")\n",
    "\n",
    "detections = detection_head(features)\n",
    "print(f\"Detection output: {detections.shape}\")\n",
    "print(f\"  Grid: {detection_head.S}x{detection_head.S}\")\n",
    "print(f\"  Per cell: {detection_head.B}*5 + {detection_head.C} = {detection_head.B*5 + detection_head.C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Semantic Segmentation\n",
    "\n",
    "Semantic segmentation assigns a class label to each pixel in the image.\n",
    "\n",
    "### 3.1 Understanding Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key components of segmentation networks:\n",
    "# 1. Encoder: Extracts features (like classification backbone)\n",
    "# 2. Decoder: Upsamples to original resolution\n",
    "\n",
    "# Upsampling methods\n",
    "x = torch.randn(1, 64, 8, 8)\n",
    "\n",
    "# Method 1: Bilinear interpolation\n",
    "up_bilinear = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "print(f\"Bilinear upsampling: {x.shape} -> {up_bilinear.shape}\")\n",
    "\n",
    "# Method 2: Transposed convolution (learnable)\n",
    "up_conv = nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1)\n",
    "up_transposed = up_conv(x)\n",
    "print(f\"Transposed conv: {x.shape} -> {up_transposed.shape}\")\n",
    "\n",
    "# Method 3: Pixel shuffle (sub-pixel convolution)\n",
    "# Rearranges (C*r^2, H, W) to (C, H*r, W*r)\n",
    "x_shuffle = torch.randn(1, 256, 8, 8)  # 256 = 64 * 2^2\n",
    "up_shuffle = nn.PixelShuffle(upscale_factor=2)(x_shuffle)\n",
    "print(f\"Pixel shuffle: {x_shuffle.shape} -> {up_shuffle.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 U-Net Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Two consecutive conv-bn-relu blocks\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    U-Net architecture for semantic segmentation.\n",
    "    \n",
    "    Features:\n",
    "    - Encoder-decoder structure\n",
    "    - Skip connections between encoder and decoder\n",
    "    - Gradually reduces then increases spatial resolution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels: int = 3, num_classes: int = 21):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
    "        self.dec4 = DoubleConv(1024, 512)  # 512 + 512 from skip\n",
    "        \n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256)\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128)\n",
    "        \n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64)\n",
    "        \n",
    "        # Output\n",
    "        self.out = nn.Conv2d(64, num_classes, 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        e4 = self.enc4(self.pool(e3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d4 = self.dec4(torch.cat([self.up4(b), e4], dim=1))\n",
    "        d3 = self.dec3(torch.cat([self.up3(d4), e3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), e2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), e1], dim=1))\n",
    "        \n",
    "        return self.out(d1)\n",
    "\n",
    "\n",
    "# Test U-Net\n",
    "unet = UNet(in_channels=3, num_classes=21)\n",
    "x = torch.randn(2, 3, 256, 256)\n",
    "out = unet(x)\n",
    "print(f\"U-Net: {x.shape} -> {out.shape}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in unet.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Using Pretrained Segmentation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained FCN\n",
    "seg_model = fcn_resnet50(weights=FCN_ResNet50_Weights.DEFAULT)\n",
    "seg_model.eval()\n",
    "seg_model.to(device)\n",
    "\n",
    "# VOC class names\n",
    "VOC_CLASSES = [\n",
    "    'background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus',\n",
    "    'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike',\n",
    "    'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'\n",
    "]\n",
    "\n",
    "print(f\"FCN-ResNet50 loaded with {len(VOC_CLASSES)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(model, image: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Run segmentation on an image.\n",
    "    \n",
    "    Returns:\n",
    "        Segmentation mask (H, W) with class indices\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Segment\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)['out']\n",
    "    \n",
    "    # Get class predictions\n",
    "    mask = output.argmax(dim=1).squeeze().cpu()\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def visualize_segmentation(image: Image.Image, mask: torch.Tensor, classes: list):\n",
    "    \"\"\"Visualize segmentation results\"\"\"\n",
    "    # Create color map\n",
    "    num_classes = len(classes)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, num_classes))\n",
    "    \n",
    "    # Create colored mask\n",
    "    colored_mask = np.zeros((*mask.shape, 3))\n",
    "    for i in range(num_classes):\n",
    "        colored_mask[mask == i] = colors[i, :3]\n",
    "    \n",
    "    # Resize mask to image size\n",
    "    mask_resized = Image.fromarray((colored_mask * 255).astype(np.uint8))\n",
    "    mask_resized = mask_resized.resize(image.size, Image.NEAREST)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask_resized)\n",
    "    axes[1].set_title('Segmentation Mask')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(image)\n",
    "    axes[2].imshow(mask_resized, alpha=0.5)\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Add legend for present classes\n",
    "    unique_classes = torch.unique(mask).tolist()\n",
    "    legend_elements = [plt.Rectangle((0, 0), 1, 1, facecolor=colors[i, :3], \n",
    "                                      label=classes[i]) \n",
    "                       for i in unique_classes if i < len(classes)]\n",
    "    axes[1].legend(handles=legend_elements, loc='upper right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Test segmentation\n",
    "try:\n",
    "    img = load_image_from_url(sample_url)\n",
    "    mask = segment_image(seg_model, img)\n",
    "    visualize_segmentation(img, mask, VOC_CLASSES)\n",
    "except Exception as e:\n",
    "    print(f\"Could not run segmentation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Segmentation Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Dice Loss for segmentation.\n",
    "    \n",
    "    Dice = 2 * |A ∩ B| / (|A| + |B|)\n",
    "    \n",
    "    Works well for imbalanced classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smooth: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: (N, C, H, W) logits\n",
    "            target: (N, H, W) class indices\n",
    "        \"\"\"\n",
    "        num_classes = pred.shape[1]\n",
    "        \n",
    "        # One-hot encode target\n",
    "        target_one_hot = F.one_hot(target, num_classes).permute(0, 3, 1, 2).float()\n",
    "        \n",
    "        # Softmax predictions\n",
    "        pred_soft = F.softmax(pred, dim=1)\n",
    "        \n",
    "        # Calculate Dice per class\n",
    "        intersection = (pred_soft * target_one_hot).sum(dim=(2, 3))\n",
    "        union = pred_soft.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
    "        \n",
    "        dice = (2 * intersection + self.smooth) / (union + self.smooth)\n",
    "        \n",
    "        # Average over classes and batch\n",
    "        return 1 - dice.mean()\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for handling class imbalance.\n",
    "    \n",
    "    FL(p) = -α(1-p)^γ * log(p)\n",
    "    \n",
    "    Down-weights easy examples, focuses on hard ones.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 1.0, gamma: float = 2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: (N, C, H, W) logits\n",
    "            target: (N, H, W) class indices\n",
    "        \"\"\"\n",
    "        ce_loss = F.cross_entropy(pred, target, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - p) ** self.gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "\n",
    "# Test losses\n",
    "pred = torch.randn(4, 21, 64, 64)\n",
    "target = torch.randint(0, 21, (4, 64, 64))\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()(pred, target)\n",
    "dice_loss = DiceLoss()(pred, target)\n",
    "focal_loss = FocalLoss()(pred, target)\n",
    "\n",
    "print(f\"Cross Entropy Loss: {ce_loss.item():.4f}\")\n",
    "print(f\"Dice Loss: {dice_loss.item():.4f}\")\n",
    "print(f\"Focal Loss: {focal_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Advanced Techniques\n",
    "\n",
    "### 4.1 Test-Time Augmentation (TTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTAWrapper:\n",
    "    \"\"\"\n",
    "    Test-Time Augmentation wrapper.\n",
    "    \n",
    "    Applies augmentations at test time and averages predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, augmentations: List[callable]):\n",
    "        self.model = model\n",
    "        self.augmentations = augmentations\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (N, C, H, W)\n",
    "        \n",
    "        Returns:\n",
    "            Averaged predictions\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        \n",
    "        for aug in self.augmentations:\n",
    "            # Apply augmentation\n",
    "            x_aug = aug(x)\n",
    "            \n",
    "            # Get prediction\n",
    "            pred = self.model(x_aug)\n",
    "            \n",
    "            # Reverse augmentation on prediction if needed\n",
    "            # (for segmentation, need to flip mask back)\n",
    "            pred = self._reverse_aug(pred, aug)\n",
    "            \n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # Average predictions\n",
    "        return torch.stack(predictions).mean(dim=0)\n",
    "    \n",
    "    def _reverse_aug(self, pred, aug):\n",
    "        \"\"\"Reverse augmentation if needed\"\"\"\n",
    "        # For horizontal flip, flip the prediction back\n",
    "        if hasattr(aug, '__name__') and 'hflip' in aug.__name__:\n",
    "            return torch.flip(pred, dims=[-1])\n",
    "        return pred\n",
    "\n",
    "\n",
    "# Define augmentations\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def hflip(x):\n",
    "    return torch.flip(x, dims=[-1])\n",
    "hflip.__name__ = 'hflip'\n",
    "\n",
    "def vflip(x):\n",
    "    return torch.flip(x, dims=[-2])\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "model.eval()\n",
    "\n",
    "tta_model = TTAWrapper(model, [identity, hflip])\n",
    "\n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "pred_tta = tta_model(x)\n",
    "print(f\"TTA prediction shape: {pred_tta.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Ensemble multiple models by averaging their predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, models: List[nn.Module], weights: Optional[List[float]] = None):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "        \n",
    "        if weights is None:\n",
    "            weights = [1.0 / len(models)] * len(models)\n",
    "        self.weights = weights\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        predictions = []\n",
    "        \n",
    "        for model, weight in zip(self.models, self.weights):\n",
    "            model.eval()\n",
    "            pred = model(x)\n",
    "            predictions.append(weight * F.softmax(pred, dim=1))\n",
    "        \n",
    "        # Weighted average of softmax probabilities\n",
    "        return torch.stack(predictions).sum(dim=0)\n",
    "\n",
    "\n",
    "# Create ensemble of different architectures\n",
    "model1 = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model1.fc = nn.Linear(model1.fc.in_features, 10)\n",
    "\n",
    "model2 = resnet18()  # Random weights\n",
    "model2.fc = nn.Linear(model2.fc.in_features, 10)\n",
    "\n",
    "ensemble = EnsembleModel([model1, model2], weights=[0.7, 0.3])\n",
    "\n",
    "x = torch.randn(4, 3, 224, 224)\n",
    "pred_ensemble = ensemble(x)\n",
    "print(f\"Ensemble prediction shape: {pred_ensemble.shape}\")\n",
    "print(f\"Probabilities sum to 1: {pred_ensemble[0].sum().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_with_mixed_precision(model, loader, criterion, optimizer, device, epochs=1):\n",
    "    \"\"\"\n",
    "    Train with automatic mixed precision (AMP).\n",
    "    \n",
    "    Uses FP16 for forward/backward, FP32 for weight updates.\n",
    "    Faster training with less memory.\n",
    "    \"\"\"\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with autocast\n",
    "            with autocast():\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Batch {batch_idx}: Loss = {loss.item():.4f}\")\n",
    "            \n",
    "            if batch_idx >= 20:  # Short demo\n",
    "                break\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"Training with Mixed Precision:\")\n",
    "    train_with_mixed_precision(model, train_loader, criterion, optimizer, device)\n",
    "else:\n",
    "    print(\"Mixed precision requires CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Fine-tune for Custom Dataset\n",
    "\n",
    "Create a complete transfer learning pipeline for a custom classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Implement a complete transfer learning pipeline\n",
    "\n",
    "class TransferLearningPipeline:\n",
    "    \"\"\"\n",
    "    Complete pipeline for transfer learning.\n",
    "    \n",
    "    Steps:\n",
    "    1. Load pretrained model\n",
    "    2. Modify for new task\n",
    "    3. Set up training with appropriate LR strategy\n",
    "    4. Train with early stopping\n",
    "    5. Evaluate with TTA\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int, strategy: str = 'finetune'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of output classes\n",
    "            strategy: 'feature_extract' or 'finetune'\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs: int = 10):\n",
    "        \"\"\"Train the model with early stopping\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x: torch.Tensor, use_tta: bool = False) -> torch.Tensor:\n",
    "        \"\"\"Make predictions, optionally with TTA\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Build a Detection Dataset\n",
    "\n",
    "Create a PyTorch dataset for object detection that handles bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Create a detection dataset\n",
    "\n",
    "class DetectionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for object detection.\n",
    "    \n",
    "    Should handle:\n",
    "    - Loading images and annotations\n",
    "    - Applying transforms to both image AND boxes\n",
    "    - Converting box format (xyxy, xywh, cxcywh)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, images: List, annotations: List, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images: List of image paths or PIL images\n",
    "            annotations: List of dicts with 'boxes' and 'labels'\n",
    "            transform: Optional transform to apply\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # YOUR CODE HERE\n",
    "        # Should return: image, target dict with 'boxes', 'labels'\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Implement Segmentation Metrics\n",
    "\n",
    "Implement IoU (Jaccard) and Dice metrics for segmentation evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Implement segmentation metrics\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    \"\"\"\n",
    "    Calculate segmentation metrics:\n",
    "    - IoU (Intersection over Union) per class\n",
    "    - Mean IoU (mIoU)\n",
    "    - Dice coefficient per class\n",
    "    - Pixel accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes: int, ignore_index: int = 255):\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def update(self, pred: torch.Tensor, target: torch.Tensor):\n",
    "        \"\"\"Update confusion matrix with batch predictions\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def compute(self) -> Dict[str, float]:\n",
    "        \"\"\"Compute all metrics\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the confusion matrix\"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 1: Transfer Learning Pipeline\n",
    "\n",
    "class TransferLearningPipeline:\n",
    "    def __init__(self, num_classes: int, strategy: str = 'finetune'):\n",
    "        self.num_classes = num_classes\n",
    "        self.strategy = strategy\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load model\n",
    "        self.model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        if strategy == 'feature_extract':\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Setup optimizer\n",
    "        if strategy == 'finetune':\n",
    "            self.optimizer = torch.optim.Adam([\n",
    "                {'params': self.model.fc.parameters(), 'lr': 1e-3},\n",
    "                {'params': [p for n, p in self.model.named_parameters() \n",
    "                           if 'fc' not in n and p.requires_grad], 'lr': 1e-5}\n",
    "            ])\n",
    "        else:\n",
    "            self.optimizer = torch.optim.Adam(self.model.fc.parameters(), lr=1e-3)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.best_acc = 0\n",
    "        self.patience_counter = 0\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs: int = 10, patience: int = 3):\n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            self.model.train()\n",
    "            train_loss = 0\n",
    "            for data, target in train_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # Validate\n",
    "            val_acc = self._evaluate(val_loader)\n",
    "            print(f\"Epoch {epoch+1}: Val Acc = {val_acc:.2f}%\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > self.best_acc:\n",
    "                self.best_acc = val_acc\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                if self.patience_counter >= patience:\n",
    "                    print(\"Early stopping!\")\n",
    "                    break\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "        return 100. * correct / total\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict(self, x: torch.Tensor, use_tta: bool = False) -> torch.Tensor:\n",
    "        self.model.eval()\n",
    "        x = x.to(self.device)\n",
    "        \n",
    "        if use_tta:\n",
    "            preds = []\n",
    "            preds.append(F.softmax(self.model(x), dim=1))\n",
    "            preds.append(F.softmax(self.model(torch.flip(x, [-1])), dim=1))\n",
    "            return torch.stack(preds).mean(dim=0)\n",
    "        else:\n",
    "            return F.softmax(self.model(x), dim=1)\n",
    "\n",
    "\n",
    "print(\"TransferLearningPipeline defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 2: Detection Dataset\n",
    "\n",
    "class DetectionDataset(Dataset):\n",
    "    def __init__(self, images: List, annotations: List, transform=None):\n",
    "        self.images = images\n",
    "        self.annotations = annotations\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        if isinstance(self.images[idx], str):\n",
    "            image = Image.open(self.images[idx]).convert('RGB')\n",
    "        else:\n",
    "            image = self.images[idx]\n",
    "        \n",
    "        # Get annotations\n",
    "        ann = self.annotations[idx]\n",
    "        boxes = torch.tensor(ann['boxes'], dtype=torch.float32)\n",
    "        labels = torch.tensor(ann['labels'], dtype=torch.int64)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            # For detection, need to transform boxes too\n",
    "            # Here we just transform the image\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = T.ToTensor()(image)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "        }\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Custom collate for variable number of boxes per image\"\"\"\n",
    "        images = [item[0] for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        return torch.stack(images), targets\n",
    "\n",
    "\n",
    "# Example usage\n",
    "dummy_images = [torch.randn(3, 224, 224) for _ in range(10)]\n",
    "dummy_annotations = [\n",
    "    {'boxes': [[10, 10, 50, 50], [100, 100, 150, 150]], 'labels': [1, 2]}\n",
    "    for _ in range(10)\n",
    "]\n",
    "\n",
    "det_dataset = DetectionDataset(dummy_images, dummy_annotations)\n",
    "print(f\"Detection dataset size: {len(det_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution 3: Segmentation Metrics\n",
    "\n",
    "class SegmentationMetrics:\n",
    "    def __init__(self, num_classes: int, ignore_index: int = 255):\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_index = ignore_index\n",
    "        self.confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def update(self, pred: torch.Tensor, target: torch.Tensor):\n",
    "        \"\"\"Update confusion matrix\"\"\"\n",
    "        # Get predictions\n",
    "        if pred.dim() == 4:  # (N, C, H, W)\n",
    "            pred = pred.argmax(dim=1)\n",
    "        \n",
    "        # Flatten\n",
    "        pred = pred.flatten()\n",
    "        target = target.flatten()\n",
    "        \n",
    "        # Ignore specified index\n",
    "        mask = target != self.ignore_index\n",
    "        pred = pred[mask]\n",
    "        target = target[mask]\n",
    "        \n",
    "        # Update confusion matrix\n",
    "        for t, p in zip(target, pred):\n",
    "            if t < self.num_classes and p < self.num_classes:\n",
    "                self.confusion_matrix[t, p] += 1\n",
    "    \n",
    "    def compute(self) -> Dict[str, float]:\n",
    "        \"\"\"Compute all metrics\"\"\"\n",
    "        cm = self.confusion_matrix\n",
    "        \n",
    "        # Per-class IoU\n",
    "        intersection = cm.diag()\n",
    "        union = cm.sum(dim=1) + cm.sum(dim=0) - cm.diag()\n",
    "        iou_per_class = intersection / (union + 1e-6)\n",
    "        \n",
    "        # Per-class Dice\n",
    "        dice_per_class = 2 * intersection / (cm.sum(dim=1) + cm.sum(dim=0) + 1e-6)\n",
    "        \n",
    "        # Pixel accuracy\n",
    "        pixel_acc = cm.diag().sum() / (cm.sum() + 1e-6)\n",
    "        \n",
    "        return {\n",
    "            'iou_per_class': iou_per_class.tolist(),\n",
    "            'mean_iou': iou_per_class.mean().item(),\n",
    "            'dice_per_class': dice_per_class.tolist(),\n",
    "            'mean_dice': dice_per_class.mean().item(),\n",
    "            'pixel_accuracy': pixel_acc.item(),\n",
    "        }\n",
    "    \n",
    "    def reset(self):\n",
    "        self.confusion_matrix.zero_()\n",
    "\n",
    "\n",
    "# Test\n",
    "metrics = SegmentationMetrics(num_classes=3)\n",
    "\n",
    "# Simulated predictions and targets\n",
    "pred = torch.randint(0, 3, (4, 64, 64))\n",
    "target = torch.randint(0, 3, (4, 64, 64))\n",
    "\n",
    "metrics.update(pred, target)\n",
    "results = metrics.compute()\n",
    "\n",
    "print(\"Segmentation Metrics:\")\n",
    "print(f\"  Mean IoU: {results['mean_iou']:.4f}\")\n",
    "print(f\"  Mean Dice: {results['mean_dice']:.4f}\")\n",
    "print(f\"  Pixel Accuracy: {results['pixel_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Transfer Learning**:\n",
    "   - Feature extraction: Fast, good for small datasets\n",
    "   - Fine-tuning: Better performance, needs more data\n",
    "   - Use differential learning rates (smaller for pretrained layers)\n",
    "\n",
    "2. **Object Detection**:\n",
    "   - IoU measures box overlap quality\n",
    "   - NMS removes duplicate detections\n",
    "   - Modern detectors use anchor boxes and feature pyramids\n",
    "\n",
    "3. **Semantic Segmentation**:\n",
    "   - Encoder-decoder architecture (like U-Net)\n",
    "   - Skip connections preserve spatial information\n",
    "   - Dice/Focal loss for imbalanced classes\n",
    "\n",
    "4. **Advanced Techniques**:\n",
    "   - TTA improves predictions by averaging augmented inputs\n",
    "   - Model ensembling combines multiple models\n",
    "   - Mixed precision speeds up training\n",
    "\n",
    "### When to Use What\n",
    "\n",
    "| Task | Architecture | Loss Function |\n",
    "|------|--------------|---------------|\n",
    "| Classification | ResNet, EfficientNet | Cross Entropy |\n",
    "| Detection | Faster R-CNN, YOLO | Smooth L1 + CE |\n",
    "| Segmentation | U-Net, DeepLab | Dice + CE |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
